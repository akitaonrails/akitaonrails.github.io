---
title: "AI Agents: Qual √© o melhor? OpenCode, Crush, Claude Code, GPT Codex, GoPilot, Cursor, WindSurf, AntiGravity?"
slug: "ai-agents-qual-e-o-melhor-opencode-crush-claude-code-gpt-codex-gopilot-cursor-windsurf-antigravity"
date: 2026-01-24T09:00:31-0300
tags:
- agents
- claude
- gpt
- codex
- opencode
- crush
---

Este post foi inspirado por causa deste tweet:

[![tweet](https://new-uploads-akitaonrails.s3.us-east-2.amazonaws.com/20260124090157_screenshot-2026-01-24_09-01-43.png)](https://x.com/lordmagus/status/2014853337058050077)

Quem acompanha meu blog ou meu X, sabe que eu venho incentivando a usar agentes open source de IA como [**Crush**](/2026/01/09/omarchy-3-um-dos-melhores-agentes-pra-programacao-crush/) ou [**OpenCode**](https://opencode.ai/), que o DHH gosta mais no Omarchy.

Mas como o tweet disse acima, sim, eles n√£o s√£o capazes de fazer tudo que as op√ß√µes propriet√°rias e fechadas conseguem.

Apesar do t√≠tulo, a id√©ia n√£o √© fazer um review de cada um, mas sim dizer em "linahs gerais", onde os principais agentes se encontram.

> TL;DR por prefer√™ncia pessoal, eu vou continuar usando Crush. Pontualmente vou usar Claude Code.

Vamos explicar por que.

### Agent Skills

Esta √© a parte f√°cil. A Anthropic inventou um padr√£o de ferramentas chamadas [**Agents Skills**](https://platform.claude.com/docs/en/agents-and-tools/agent-skills/overview). Praticamente todos os agentes comerciais e open source suportam skills.

No meu setup pessoal, pra Crush, configurei da seguinte forma:

```bash
cd ~/.config/crush/
git clone https://github.com/anthropics/skills.git anthropic_skills
ln -s anthropic_skills/skills skills
```

Da√≠ no meu `~/.config/crush/crush.json` configuro assim:

```json
{
  "$schema": "https://charm.land/crush.json",
  "options": {
    "skills_paths": [
      "~/.config/crush/skills"
    ]
  },
  ...
}
```

As skills da Anthropic s√£o open source (pelo menos eles contribuem alguma coisa pra open source, de vez em quando, entre uma controv√©rsia e outra ... ü§∑‚Äç‚ôÇ). E na pr√°tica n√£o tem nenhuma skill muito interessante. Vejam:

![anthropic skills](https://new-uploads-akitaonrails.s3.us-east-2.amazonaws.com/20260124091029_screenshot-2026-01-24_09-10-19.png)

S√£o ferramentas pra gerar documentos Word ou PDF e coisas assim. A id√©ia no Claude Code √© que existe um Marketplace de plugins, e voc√™ pode instalar v√°rios outros plugins de terceiros. Eis um exemplo da Supabase:

[![supabase skills](https://new-uploads-akitaonrails.s3.us-east-2.amazonaws.com/20260124091331_screenshot-2026-01-24_09-13-21.png)](https://github.com/supabase/agent-skills)

No meu exemplo simples, estou usando s√≥ skills da anthropic, mas eu posso s√≥ sair juntando mais e mais skills e jogar dentro de `~/.config/crush/skills/` e pronto. Veja como eu ativo dentro do meu Crush:

![crush skill call](https://new-uploads-akitaonrails.s3.us-east-2.amazonaws.com/20260124091515_screenshot-2026-01-24_08-55-20.png)

Viram? Igual no Claude Code, a skill √© chamada automaticamente.

> Skills autom√°ticas s√£o facas de dois gumes: n√£o instale tudo que ver pela frente.

TUDO em agentes √© baseado em **SYSTEM PROMPT**. S√£o as instru√ß√µes que os agentes repetem a cada nova sess√£o. A diferen√ßa de usar agentes e usar direto no chat do site deles s√£o os prompts.

Ano passado eu [expliquei neste post](https://akitaonrails.com/2025/04/25/hello-world-de-llm-criando-seu-proprio-chat-de-i-a-que-roda-local/) como um agente funciona do zero. Leia pra entender.

Pra usar skills, a LLM tem que saber que elas existem. E pra isso precisa ser informado no SYSTEM PROMPT. Isso **n√£o √© de gra√ßa**.

Pro SYSTEM PROMPT ter as skills, o agente precisa concatenar metadados da skill: nome, descri√ß√£o, path pros scripts, tudo num formato XML.

* nome: 5 a 10 tokens (m√°ximo de 64 tokens)
* descri√ß√£o: 50 a 200 tokens (m√°ximo de 1024 tokens)
* path: 10 a 20 tokens
* overhead de XML: uns 15 tokens

Estimativa grosseira: 80 a 250 tokens por skill.

Estimativa se tiver 50 skills instaladas: 4 mil a 12.500 tokens pra cada nova sess√£o!

Agentes s√£o muito √∫teis, mas isso √© uma das coisas que vai tornando as coisas caras: elas ficam melhores, quanto mais SYSTEM PROMPT de instru√ß√µes receberem. Mas isso n√£o tem mem√≥ria: precisa instruir TODA vez que voc√™ abre o Claude Code ou Codex ou qualquer outro. Sempre vai consumir tokens! Mesmo se voc√™ s√≥ abrir a ferramenta e n√£o fizer nada, vai gastar tokens. Esse √© o modelo de neg√≥cio de todos eles.

"MAS", isso dito, sim, de fato skills s√£o √∫teis. Assim como LSPs, MCPs, ACPs. S√≥ tenha consci√™ncia que nada disso √© de gra√ßa. E tamb√©m nada disso √© m√°gica espec√≠fica de alguma ferramenta. √â tudo aberto, e tem que ser, s√£o prompts em texto.

### GPT Codex "HARNESS"

Este √© um ponto de controv√©rsia, mais uma chatice da OpenAI. Dependendo do ponto de vista √© bom, mas tamb√©m √© ruim.

"Harness", como o pr√≥prio nome diz, √© um "arreio", uma "correia de seguran√ßa", como se o GPT fosse um cavalo selvagem e estamos tentando domar ele.

√â tudo que segura a LLM bruta pra torn√°-la mais efetiva especificamente pra c√≥digo:

* SYSTEM PROMPT - a parte mais importante, as intru√ß√µes que definem o comportamento, personalidade, limita√ß√µes
* Defini√ß√£o de Tools/ferramentas - ferramentas espec√≠ficas que o modelo pode chamar (apply_patch, rg, git, etc)
* Formato de Patch - um formato diff espec√≠fico que o modelo foi treinado (um dos pontos que eu n√£o gosto: treinar em formato n√£o padr√£o)
* Loop/Orquestra√ß√£o - chamar o modelo repetidament, como lidar com resultado das ferramentas, gerenciamento de contexto

Os modelos GPT Codex foram tunados especificament pra esse harness **propriet√°rio** - s√≥ ele se comporta assim. Por isso que usar esses LLMs em ferramentas diferentes do Codex CLI pode n√£o trazer o mesmo resultado.

> Mas d√° pra usar esses harness foram do Codex? Parcialmente, sim.

**1. O SYSTEM PROMPT √© p√∫blico**

Est√° [neste link](https://github.com/openai/codex/blob/main/codex-rs/core/prompt.md). Principais elementos:

* seja conciso, direto, amig√°vel
* use apply_patch para editar arquivos (e n√£o sed/echo)
* use rg em vez de grep pra pesquisas
* obede√ßa arquivos AGENTS.md
* use update_plan para tarefas de m√∫ltiplos passos
* nunca use git commit a menos que seja explicitamente ordenado

**2. O Formato apply_patch**

Os modelos da OpenAI s√£o treinados neste formato espec√≠fico de patch:

```diff
*** Begin Patch
*** Update File: src/main.py
@@ def calculate():
     result = 0
-    return result
+    return result + 1
*** End Patch
```

Princ√≠pios:

* sem n√∫mero nas linhas - em vez disso, use linhas de contexto
* delimitadores claros pra c√≥digo velho vs novo
* suporta opera√ß√µes de criar, atualizar, deletar

**3. Configura√ß√£o de Ferramenta**

Ferramentas padr√£o do Codex:

* apply_patch - edi√ß√£o de arquivos (o modelo foi treinado nisso)
* rg - ripgrep pra pesquisar c√≥digo
* read_file - l√™ conte√∫do de arquivos
* list_dir - lista arquivos do diret√≥rio
* glob_file_search - pattern matching
* git - controle de vers√£o
* todo_write/update_plan - gerenciamento de tarefas

Ou seja, no caso espec√≠fico do Crush, ainda n√£o tem suporte ao harness propriet√°rio da OpenAI. Os modelos da OpenAI tiveram fine-tuning em cima desse harness em espec√≠fico. Pra tirar melhor proveito, precisa mandar chamar "apply_patch" e n√£o usar "sed", por exemplo. Pra achar c√≥digo direito, ele sabe usar "rg", mas n√£o vai saber usar "grep" da mesma forma.

> Por isso, pra usar o harness do Codex, obrigatoriamente precisa usar o Codex CLI.

D√° pra fazer engenharia reversa e implementar em Crush ou OpenCode. Eu acho que ainda n√£o tem esse suporte. O saco √© que vai ser como com Microsoft e Windows. Sempre que no mundo open source conseguirmos replicar o mesmo comportamento, eles v√£o lan√ßar uma nova vers√£o que quebra o comportamento antigo e vai virar a mesma hist√≥ria cansativa de gato e rato.

### Agents Wars

Lembram do "Browser Wars" dos anos 90 e anos 2000? √â a mesma coisa:

* Claude Code √© o Internet Explorer 11
* GPT Codex √© o Netscape
* Cursor, Windsurf, Copilot s√£o os Operas
* OpenCode/Crush s√£o Chromium em 2006

Os princ√≠pios s√£o os mesmos:

* cada modelo LLM de c√≥digo foi treinado num "harness" diferente
* teoricamente, somente a OpenAI e parceiros licenciados da OpenAI tem acesso √† especifica√ß√£o exata desse harness. Por isso Codex ou Cursor ou CoPilot v√£o se comportar diferente de OpenCode quando usam modelos da OpenAI.
* tudo s√£o prompts: se soubermos os prompts de instru√ß√£o exatos, podemos replicar isso no mundo open source - j√° deve ter gente fazendo
* mas √© persegui√ß√£o de gato e rato. toda vez vai sair vers√£o nova. √â o mesmo problema de LibreOffice vs Microsoft Office, que depois de d√©cadas, continua n√£o sendo 100% compat√≠vel

Por isso n√£o tem jeito:

* quer tirar o m√°ximo proveito de Claude? Use Claude Code
* quer tirar o m√°ximo proveito de GPT? Use Codex CLI

LLMs s√£o caros de treinar. Na casa dos bilh√µes de caro. √ìbvio que eles v√£o fechar o m√°ximo poss√≠vel pra conseguir o maior retorno de investimento. √â at√© justo.

Por isso modelos "abertos" s√£o importantes: pra ajudar a for√ßar um padr√£o aberto de tooling e harness. N√£o existe, na pr√°tica, nenhum modelo verdadeiramente aberto. Todos s√£o "gr√°tis" (como em "cerveja gr√°tis") e n√£o "livres" (como em "liberdade de express√£o"). Todo mundo quer tirar fatia de mercado do concorrente, esse √© o incentivo.

### Conclus√£o

Na pr√°tica, pra variar, **DEPENDE** do seu uso. Se GPT d√° melhores resultados pro seu tipo de projeto, use Codex CLI ou parceiros da OpenAI como CoPilot ou Cursor que - provavelmente - usam o mesmo harness.

Se Claude d√° melhores resultados pra voc√™, use Claude Code.

Se voc√™ n√£o se v√™ usando skills espec√≠ficas ou coisas assim, existem alternativas que d√£o resultados t√£o bons quanto Claude, como GLM 4.7 ou MiniMax v2.1. O atrativo pras alternativas √© n√£o ficar fechado em ferramentas propriet√°rias de novo e poder usar OpenCode ou Crush. Essas s√£o as mais "open source"-friendly - se voc√™ se importa com isso.

Estamos numa bolha de IAs, isso √© √≥bvio. E em particular no mundo de dev, estamos no meio de uma "Guerra de Agentes". Codex quer ser o pr√≥ximo Office. Claude Code quer ser o pr√≥ximo Internet Explorer.

Eu pessoalmente n√£o tenho nada espec√≠fico que preciso de Claude ou GPT. A performance de Claude via Crush est√° muito boa pra mim, por isso vou continuar no Crush. Voc√™ deve escolher baseado nas suas pr√≥prias necessidades e testes.

Voc√™ deveria ser um dev de verdade e testar tecnicamente, e n√£o seguir opini√µes.
